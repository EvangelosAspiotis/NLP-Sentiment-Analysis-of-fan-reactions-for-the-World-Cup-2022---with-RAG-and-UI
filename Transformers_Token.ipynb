{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601a4aa4-958c-4de8-b394-ee34b4611027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nskol\\anaconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from wordcloud import WordCloud\n",
    "from transformers import AutoTokenizer\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84acea7e-b152-495c-9c50-66b9fe4720b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/992.0 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 524.3/992.0 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 992.0/992.0 kB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "# May be needed afterwards. \n",
    "#!pip install transformers\n",
    "#!pip install accelerate\n",
    "#!pip install --upgrade jinja2\n",
    "#!pip install -U sentence-transformers\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install scikit-learn\n",
    "#!pip install --upgrade bitsandbytes\n",
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5f7947-8827-4aeb-8910-e089e08823b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\nskol\\Downloads\\v2.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82702e92-ca31-43e2-a96e-79d221c07859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drinking today</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amaze launch video. show much face canada mens...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worth read watch</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>golden maknae shin bright</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bbc care much human right homosexual right wom...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Sentiment\n",
       "0                                     drinking today   neutral\n",
       "1  amaze launch video. show much face canada mens...  positive\n",
       "2                                   worth read watch  positive\n",
       "3                          golden maknae shin bright  positive\n",
       "4  bbc care much human right homosexual right wom...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac37a3-8cae-45e5-a444-c3ced3e9fc64",
   "metadata": {},
   "source": [
    "# Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcfe3fb1-902a-48c5-aaf4-6bab8162cbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the value for HF_TOKEN:  ········\n"
     ]
    }
   ],
   "source": [
    "os.environ['HF_TOKEN'] = getpass.getpass(\"Enter the value for HF_TOKEN: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab98803-baea-4c4d-827d-4a507f3b645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_HOME\"] = \"/content/my_huggingface_cache\"\n",
    "my_model = \"mistralai/Mistral-7B-Instruct-v0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc56059d-c026-4c68-b3da-d65adf24ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(my_model,\n",
    "                                          token=os.environ[\"HF_TOKEN\"],\n",
    "                                          cache_dir=os.environ[\"HF_HOME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "640e08d4-f800-47aa-8ffa-129373c24bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Hello', ',', '▁world', '!', '▁Let', \"'\", 's', '▁token', 'ize', '▁this', '▁text', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"Hello, world! Let's tokenize this text.\")\n",
    "print(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
